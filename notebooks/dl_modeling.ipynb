{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "from jiwer import wer\n",
    "import random\n",
    "\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "from data_gen import DataGenerator\n",
    "from tokenizer import Tokenizer\n",
    "from logspectrogram import LogMelSpectrogram\n",
    "from ctc_loss import CTC_loss\n",
    "from model_implementation import simple_rnn_model, CNN_net, BidirectionalRNN2, cnn_rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the CTC loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_step = 256\n",
    "ctc = CTC_loss(frame_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data prepared for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_obj = helper.read_obj(\"../data/translation_obj.pkl\")\n",
    "audio_obj = helper.read_obj(\"../data/audio_dict.pkl\")\n",
    "metadata = pd.read_csv(\"../data/meta_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>label</th>\n",
       "      <th>channel</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>እኔ ጥሩ ኢትዮጵያዊ ነኝ</td>\n",
       "      <td>tr_7742_tr78043</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>ይሄ ትክክል ነው</td>\n",
       "      <td>tr_6930_tr70031</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>የ ኢትዮጵያ ን ሰራዊት ወነጀለ</td>\n",
       "      <td>tr_8006_tr81007</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>ደንቡ ም እንዲ ህ የሚ ል ነው</td>\n",
       "      <td>tr_7783_tr78084</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>ኢነጋማ ህጋዊ እውቅና አገኘ</td>\n",
       "      <td>tr_8030_tr81031</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>2.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>ከ ግዛታቸው ዋ ና ከተማ ጋሪ ስ ሆነው በ ስልክ ሚስተር ሞሪስ ከ ስደተኞ...</td>\n",
       "      <td>tr_2212_tr23013</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>20.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>የተ ለቀቁት ምርኮኞች በ አካባቢያቸው ሰላማዊ ኑሮ እንዲ ኖሩ የ ትራንስፖ...</td>\n",
       "      <td>tr_2560_tr26061</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>21.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>የ ትምህርት ደረጃቸው ንና የ አገልግሎት ሁኔታ ቸውን ስን መረምር የሚ ደ...</td>\n",
       "      <td>tr_2565_tr26066</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>22.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>ማጋነን ባይሆን ብኝ ለ ፕሮፌሰሩ የተሰጠ ውን አክብሮት ሳስበው የ አሜሪካ...</td>\n",
       "      <td>tr_6166_tr62067</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>22.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>ባጭሩ ድርጅታችን እየ በ ከተ ስርአታችን አመራ ራችን ባህርይ ውን እየ ቀ...</td>\n",
       "      <td>tr_6863_tr69064</td>\n",
       "      <td>1</td>\n",
       "      <td>32000</td>\n",
       "      <td>24.192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            translation            label  \\\n",
       "1233                                    እኔ ጥሩ ኢትዮጵያዊ ነኝ  tr_7742_tr78043   \n",
       "631                                          ይሄ ትክክል ነው  tr_6930_tr70031   \n",
       "730                                 የ ኢትዮጵያ ን ሰራዊት ወነጀለ  tr_8006_tr81007   \n",
       "3680                                ደንቡ ም እንዲ ህ የሚ ል ነው  tr_7783_tr78084   \n",
       "2336                                  ኢነጋማ ህጋዊ እውቅና አገኘ  tr_8030_tr81031   \n",
       "...                                                 ...              ...   \n",
       "4611  ከ ግዛታቸው ዋ ና ከተማ ጋሪ ስ ሆነው በ ስልክ ሚስተር ሞሪስ ከ ስደተኞ...  tr_2212_tr23013   \n",
       "2773  የተ ለቀቁት ምርኮኞች በ አካባቢያቸው ሰላማዊ ኑሮ እንዲ ኖሩ የ ትራንስፖ...  tr_2560_tr26061   \n",
       "2628  የ ትምህርት ደረጃቸው ንና የ አገልግሎት ሁኔታ ቸውን ስን መረምር የሚ ደ...  tr_2565_tr26066   \n",
       "1408  ማጋነን ባይሆን ብኝ ለ ፕሮፌሰሩ የተሰጠ ውን አክብሮት ሳስበው የ አሜሪካ...  tr_6166_tr62067   \n",
       "982   ባጭሩ ድርጅታችን እየ በ ከተ ስርአታችን አመራ ራችን ባህርይ ውን እየ ቀ...  tr_6863_tr69064   \n",
       "\n",
       "      channel  sample_rate  duration  \n",
       "1233        1        32000     1.792  \n",
       "631         1        32000     1.792  \n",
       "730         1        32000     1.920  \n",
       "3680        1        32000     1.920  \n",
       "2336        1        32000     2.048  \n",
       "...       ...          ...       ...  \n",
       "4611        1        32000    20.992  \n",
       "2773        1        32000    21.120  \n",
       "2628        1        32000    22.784  \n",
       "1408        1        32000    22.912  \n",
       "982         1        32000    24.192  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_metadata = metadata.sort_values(by=\"duration\")\n",
    "labels = sorted_metadata['label'].to_list()\n",
    "sorted_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = []\n",
    "for label in labels:\n",
    "    audios.append(audio_obj[label][0])\n",
    "    \n",
    "translations = []\n",
    "for label in labels:\n",
    "    translations.append(translation_obj[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize each character into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample snt: እኔ ጥሩ ኢትዮጵያዊ ነኝ\n",
      "encoded snt: [11, 103, 1, 44, 52, 1, 36, 3, 38, 43, 6, 63, 1, 20, 100]\n",
      "decoed snt: እኔ ጥሩ ኢትዮጵያዊ ነኝ\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(translations)\n",
    "# Build the charachter mapping\n",
    "int_to_char, char_to_int = tokenizer.build_dict()\n",
    "sample = translations[0]\n",
    "encoded = tokenizer.encode(sample, char_to_int)\n",
    "decoded = tokenizer.decode_text(encoded, int_to_char)\n",
    "\n",
    "print(f\"sample snt: {sample}\")\n",
    "print(f\"encoded snt: {encoded}\")\n",
    "print(f\"decoed snt: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.serialize_obj('../data/int_to_char.pkl', int_to_char)\n",
    "helper.serialize_obj('../data/char_to_int.pkl', char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 32000\n",
    "fft_size = 512\n",
    "frame_step = 256\n",
    "n_mels = 100\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "data_len = len(translations)\n",
    "output_dim = len(char_to_int) + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_dim, custom_model, preprocess_model, mfcc=False, calc=None):\n",
    "\n",
    "    input_audios = Input(name='the_input', shape=(None,))\n",
    "    pre = preprocess_model(input_audios)\n",
    "    pre = tf.squeeze(pre, [3])\n",
    "\n",
    "    y_pred = custom_model(pre)\n",
    "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
    "    model.output_length = calc\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, audio, tokenizer, int_to_char, actual=None):\n",
    "    \n",
    "    pred_audios = tf.convert_to_tensor([audio])\n",
    "    \n",
    "    y_pred = model.predict(pred_audios)\n",
    "\n",
    "    input_shape = tf.keras.backend.shape(y_pred)\n",
    "    input_length = tf.ones(shape=input_shape[0]) * tf.keras.backend.cast(input_shape[1], 'float32')\n",
    "    prediction = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=False)[0][0]\n",
    "        \n",
    "    pred = K.eval(prediction).flatten().tolist()\n",
    "    pred = [i for i in pred if i != -1]\n",
    "    \n",
    "    predicted_text = tokenizer.decode_text(pred, int_to_char)\n",
    "    \n",
    "    error = None\n",
    "    if actual != None:\n",
    "        error = wer(actual, predicted_text)\n",
    "   \n",
    "    return predicted_text, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
    "\n",
    "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
    "    featLayer = LogMelSpectrogram(\n",
    "        fft_size=fft_size,\n",
    "        hop_size=frame_step,\n",
    "        n_mels=n_mels,\n",
    "        \n",
    "        sample_rate=sample_rate,\n",
    "        f_min=0.0,\n",
    "        \n",
    "        f_max=int(sample_rate / 2),\n",
    "    )(input_data)\n",
    "    \n",
    "    x = BatchNormalization(axis=2)(featLayer)\n",
    "    model = Model(inputs=input_data, outputs=x, name=\"preprocessing_model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_builder, \n",
    "          data_gen,\n",
    "          batch_size = 32,\n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          save_path=\"../models/model.h5\",\n",
    "          optimizer=RMSprop(learning_rate=0.0001, decay=1e-6, clipnorm=5),\n",
    "          ):    \n",
    "      #     SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "              \n",
    "    model = ctc.add_ctc_loss(model_builder)\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=save_path, verbose=0)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    hist = model.fit_generator(generator=data_gen,\n",
    "                               callbacks=[checkpointer],\n",
    "\n",
    "                               epochs=epochs,\n",
    "                               verbose=verbose, \n",
    "                               use_multiprocessing=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 18:42:36.932036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:36.977257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:36.977540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:36.978849: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-09 18:42:36.979737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:36.979970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:36.980124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:37.581659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:37.581881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:37.582049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-09 18:42:37.582181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4577 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"preprocessing_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, None)]            0         \n",
      "                                                                 \n",
      " log_mel_spectrogram (LogMel  (None, None, 100, 1)     0         \n",
      " Spectrogram)                                                    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 100, 1)     400       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 400\n",
      "Trainable params: 200\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dg = DataGenerator(translations, audios, batch_size, shuffle=True)\n",
    "preprocess_model = preprocessing_model(sample_rate, fft_size, frame_step, n_mels)\n",
    "preprocess_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_rnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 100)]       0         \n",
      "                                                                 \n",
      " rnn (GRU)                   (None, None, 224)         219072    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 224)        896       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 224)        50400     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 224)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,368\n",
      "Trainable params: 269,920\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speech_simple_rnn = simple_rnn_model(n_mels, output_dim)\n",
    "speech_simple_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_builder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None)]            0         \n",
      "                                                                 \n",
      " preprocessing_model (Functi  (None, None, 100, 1)     400       \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (None, None, 100)        0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " simple_rnn_model (Functiona  (None, None, 224)        270368    \n",
      " l)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,768\n",
      "Trainable params: 270,120\n",
      "Non-trainable params: 648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_speech_model = build_model(output_dim, speech_simple_rnn, preprocess_model)\n",
    "simple_rnn_speech_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " preprocessing_model (Functiona  (None, None, 100, 1  400        ['the_input[0][0]']              \n",
      " l)                             )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, None, 100)   0           ['preprocessing_model[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " simple_rnn_model (Functional)  (None, None, 224)    270368      ['tf.compat.v1.squeeze[0][0]']   \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['input_length[0][0]']           \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['simple_rnn_model[0][0]',       \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'lambda[0][0]',                 \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 270,768\n",
      "Trainable params: 270,120\n",
      "Non-trainable params: 648\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/09 18:42:42 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b6424de76e2d4ca28e51da82422595b7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2022-06-09 18:42:42.623405: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 101580800 exceeds 10% of free system memory.\n",
      "2022-06-09 18:42:42.809911: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 101580800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 18:42:46.339741: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 42598400 exceeds 10% of free system memory.\n",
      "2022-06-09 18:42:46.378995: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 42598400 exceeds 10% of free system memory.\n",
      "2022-06-09 18:42:46.439298: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34406400 exceeds 10% of free system memory.\n",
      "2022-06-09 18:42:48.713053: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 36s 594ms/step - loss: 2022.0078\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 29s 593ms/step - loss: 575.1155\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 270.6473\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 243.9439\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 232.0405\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 29s 538ms/step - loss: 226.1447\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 29s 554ms/step - loss: 222.1227\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 219.6202\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 218.0432\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 28s 548ms/step - loss: 216.6853\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 215.7422\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 214.8573\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 26s 531ms/step - loss: 214.0132\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 27s 516ms/step - loss: 213.1302\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 212.4980\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 27s 550ms/step - loss: 212.0483\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 211.2321\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 210.6898\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 27s 523ms/step - loss: 209.9562\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 209.5408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 18:52:05.836943: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0v72zlj3/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0v72zlj3/model/data/model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fb458716df0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "2022/06/09 18:52:14 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp0v72zlj3/model, flavor: keras), fall back to return ['tensorflow==2.8.0', 'keras==2.8.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fb45831e6d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('Speech Model-RNN-baseline')\n",
    "mlflow.tensorflow.autolog()\n",
    "train(simple_rnn_speech_model, dg, epochs=20, save_path=\"../models/simple_rnn_model.h5\",  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual ለ ወይዘሪት አዲስ ና ለ ሌሎች ተወዳዳሪ ዎች ስጦታ ተዘጋጅ ቷል\n",
      "predicted  \n",
      "WER:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "simple_rnn_speech_model.load_weights(\"../models/simple_rnn_model.h5\")\n",
    "\n",
    "\n",
    "actual_translation = translations[1401]\n",
    "sample_test_audio = audios[0]\n",
    "predicted, error = predict(simple_rnn_speech_model, sample_test_audio , tokenizer, int_to_char, actual=actual_translation)\n",
    "\n",
    "print(\"actual\", actual_translation)\n",
    "print(\"predicted\", predicted)\n",
    "print(\"WER: \", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CNN + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 100)]       0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 250)         100250    \n",
      "                                                                 \n",
      " bn_conv_1d (BatchNormalizat  (None, None, 250)        1000      \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " rnn (SimpleRNN)             (None, None, 400)         260400    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 400)        1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 224)        89824     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 224)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 453,074\n",
      "Trainable params: 451,774\n",
      "Non-trainable params: 1,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speech_cnn_rnn = cnn_rnn_model(n_mels, 250, 4, 1, 'same', 400, output_dim)\n",
    "speech_cnn_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_builder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None)]            0         \n",
      "                                                                 \n",
      " preprocessing_model (Functi  (None, None, 100, 1)     400       \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze (TFOpL  (None, None, 100)        0         \n",
      " ambda)                                                          \n",
      "                                                                 \n",
      " model (Functional)          (None, None, 224)         453074    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 453,474\n",
      "Trainable params: 451,974\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speech_cnn_rnn_model = build_model(output_dim, speech_cnn_rnn, preprocess_model)\n",
    "speech_cnn_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " preprocessing_model (Functiona  (None, None, 100, 1  400        ['the_input[0][0]']              \n",
      " l)                             )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, None, 100)   0           ['preprocessing_model[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, None, 224)    453074      ['tf.compat.v1.squeeze[0][0]']   \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['input_length[0][0]']           \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'lambda[0][0]',                 \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 453,474\n",
      "Trainable params: 451,974\n",
      "Non-trainable params: 1,500\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/09 16:25:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8da17ce1c0c5457c841174f26b6b600a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2022-06-09 16:25:05.493214: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93388800 exceeds 10% of free system memory.\n",
      "2022-06-09 16:25:05.605814: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93388800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 16:25:08.016503: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67174400 exceeds 10% of free system memory.\n",
      "2022-06-09 16:25:08.056170: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67174400 exceeds 10% of free system memory.\n",
      "2022-06-09 16:25:08.125866: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 70451200 exceeds 10% of free system memory.\n",
      "2022-06-09 16:25:10.042784: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-06-09 16:25:11.721993: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 68s 1s/step - loss: 907.4033\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 57s 1s/step - loss: 244.9386\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 55s 1s/step - loss: 228.4026\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 56s 1s/step - loss: 227.8585\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 56s 1s/step - loss: 218.9279\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 56s 1s/step - loss: 222.1537\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 57s 1s/step - loss: 215.2350\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 56s 1s/step - loss: 213.9390\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 57s 1s/step - loss: 213.8091\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 211.7343\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 212.1685\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 56s 1s/step - loss: 211.8701\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 210.3362\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 208.9363\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 57s 1s/step - loss: 208.1365\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 207.9654\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 57s 1s/step - loss: 546.2103\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 56s 1s/step - loss: 251.8830\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 56s 1s/step - loss: 226.3120\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 57s 1s/step - loss: 207.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 16:44:40.550351: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpt7xz28hc/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/09 16:44:50 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpt7xz28hc/model, flavor: keras), fall back to return ['tensorflow==2.8.0', 'keras==2.8.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f5dac579940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('Speech Model-CNN + RNN-baseline')\n",
    "mlflow.tensorflow.autolog()\n",
    "train(speech_cnn_rnn_model, dg, epochs=20, save_path=\"../models/cnn_rnn_model.h5\",  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual በ ፍራቻ ነው እንዳን ጫወት የ ተደረገው\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual አንዱ በ ፔናልቲ የተገኘ ነው\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual እንዲ ህ ና በ እንዲ ህም እለቱ ታ ደረ\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual ኢትዮጵያውያ ን ከ አስመራ እየ ተባረሩ ነው\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual በ አደባባይ ም ባሪያዬ ነው እያ ልክ አት ሟገት\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual አሁን ግን ህክምና የማ ገኘው ከ እናት ተፈጥሮ ነው አሉ\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual ኢትዮጵያ ሀገራችን መኩሪያ ችን ና ት\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual ታፈሰ ልብሱ ን ሲያ ጥብ ቆየ\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual ሀይሌ ን እንደሚ ፈሩ ማን ንም አይፈሩ ም\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n",
      "actual አዲሱ ቦታው እንዳል ተስማማ ው ይናገራል\n",
      "predicted \n",
      "WER: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speech_cnn_rnn_model.load_weights(\"../models/cnn_rnn_model.h5\")\n",
    "\n",
    "for k in range(10):\n",
    "    \n",
    "\n",
    "    i = random.randint(0, 1000)\n",
    "    \n",
    "    actual_translation = translations[i]\n",
    "    sample_test_audio = audios[i]\n",
    "\n",
    "    predicted, error = predict(speech_cnn_rnn_model, sample_test_audio,\n",
    "                               tokenizer, int_to_char, actual=actual_translation)\n",
    "   \n",
    "    print(\"actual\", actual_translation)\n",
    "    print(\"predicted\", predicted)\n",
    "    print(f\"WER: {error:.2f}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CNN + BRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since this model requires expenisive resource for training, we minimize the batch size to 32\n",
    "\n",
    "batch_size = 16\n",
    "dg = DataGenerator(translations, audios, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 128, 1)]    0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, 128, 128)    6400      \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, 128, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, 128, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, None, 64, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, 64, 64)      204864    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, 64, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, None, 64, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, None, 32, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, 32, 64)      36928     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, 32, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, None, 32, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, None, 16, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 1024)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 249,216\n",
      "Trainable params: 248,704\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, TensorShape([None, None, 1024]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model, cnn_shape = CNN_net(n_mels)\n",
    "cnn_model.summary(), cnn_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BidirectionalRNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 1024)]      0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 800)        4560000   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 800)        3843200   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, None, 800)        3843200   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, None, 800)        3843200   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 222)        177822    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 222)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,280,222\n",
      "Trainable params: 16,273,822\n",
      "Non-trainable params: 6,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BI_RNN_2 = BidirectionalRNN2(1024, batch_size=batch_size, output_dim=output_dim)\n",
    "BI_RNN_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(output_dim, cnn_model, custom_model, preprocess_model, mfcc=False, calc=None):\n",
    "\n",
    "    input_audios = Input(name='the_input', shape=(None,))\n",
    "    pre = preprocess_model(input_audios)\n",
    "    pre = tf.squeeze(pre, [3])\n",
    "\n",
    "    cnn_output = cnn_model(pre)\n",
    "\n",
    "    y_pred = custom_model(cnn_output)\n",
    "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
    "    model.output_length = calc\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_builder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None)]            0         \n",
      "                                                                 \n",
      " preprocessing_model (Functi  (None, None, 128, 1)     512       \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " tf.compat.v1.squeeze_2 (TFO  (None, None, 128)        0         \n",
      " pLambda)                                                        \n",
      "                                                                 \n",
      " cnn (Functional)            (None, None, 1024)        249216    \n",
      "                                                                 \n",
      " BidirectionalRNN (Functiona  (None, None, 222)        16280222  \n",
      " l)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,529,950\n",
      "Trainable params: 16,522,782\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_bi_rnn_model = build_model2(output_dim, cnn_model, BI_RNN_2, preprocess_model)\n",
    "cnn_bi_rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Speech Model-CNN + BRNN-baseline')\n",
    "mlflow.tensorflow.autolog()\n",
    "train(cnn_bi_rnn_model, dg, epochs=20, save_path=\"../models/cnn_bi_rnn_model.h5\",  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_bi_rnn_model.load_weights(\"../models/cnn-bi-rnn.h5\")\n",
    "for k in range(10):\n",
    "    \n",
    "\n",
    "    i = random.randint(0, 3000)\n",
    "    \n",
    "    actual_translation = translations[i]\n",
    "    sample_test_audio = audios[i]\n",
    "\n",
    "    predicted, error = predict(cnn_bi_rnn_model, sample_test_audio,\n",
    "                               tokenizer, int_to_char, actual=actual_translation)\n",
    "   \n",
    "    print(\"actual\", actual_translation)\n",
    "    print(\"predicted\", predicted)\n",
    "    print(f\"WER: {error:.2f}\")\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4013b6f8acbae43f7c648f99fd383e8ec3d5fcc3a746a9453def012ca3c2930d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
