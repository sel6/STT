{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sel6/STT/blob/main/modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VsREPJdlJCw",
        "outputId": "ec2d50a7-c9e9-4321-e834-207f215ad340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting python-Levenshtein==0.12.2\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149858 sha256=b9e7717e5e2062f3b576fa08182589677340e4d2ad38c5a91ab0e1376c839091\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from jiwer import wer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JONPcY77lSCT",
        "outputId": "18b4b8f0-f1d8-4678-aa52-40d9197bb90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72zyhw88lTWg",
        "outputId": "1b724092-f7d3-4351-81ef-50dd1d7c815c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.md', 'data', 'kaldi-script', 'lang', 'lm', '.git']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"drive/MyDrive/AMHARIC\")\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jradKMvz6jfJ"
      },
      "outputs": [],
      "source": [
        "def replacer(text):\n",
        "    replace_list = \"\"\"ሐ ሑ ሒ ሓ ሔ ሕ ሖ ጸ ጹ ጺ ጻ ጼ ጽ ጾ ኰ ኲ ጿ ኸ\"\"\".split(\" \")\n",
        "    ph = \"\"\"ሀ ሁ ሂ ሀ ሄ ህ ሆ ፀ ፁ ፂ ፃ ፄ ፅ ፆ ኮ ኳ ፇ ኧ\"\"\".split(\" \")\n",
        "    for l in range(len(replace_list)):\n",
        "       text = text.replace(replace_list[l], ph[l])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1MAF05gplUBw"
      },
      "outputs": [],
      "source": [
        "meta_data = pd.read_csv(\"data/metares.csv\")\n",
        "meta_data. drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "meta_data = meta_data.sample(n=100).reset_index().drop(\"index\", axis=1)\n",
        "meta_data[\"text\"] = meta_data[\"text\"].apply(lambda x:replacer(x))\n",
        "text=[]\n",
        "for i in range(len(meta_data)):\n",
        "  text.append(meta_data[\"text\"][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LrIUXFbClUeo"
      },
      "outputs": [],
      "source": [
        "split = int(len(meta_data) * 0.90)\n",
        "df_train = meta_data[:split]\n",
        "df_val = meta_data[split:]\n",
        "\n",
        "#print(f\"Size of the training set: {len(df_train)}\")\n",
        "#print(f\"Size of the training set: {len(df_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaSJKq1wqCNf",
        "outputId": "921a2673-336f-4113-b2d7-b7d87df536ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', ' ', 'ሀ', 'ሁ', 'ሂ', 'ሄ', 'ህ', 'ሆ', 'ለ', 'ሉ', 'ሊ', 'ላ', 'ሌ', 'ል', 'ሎ', 'ሏ', 'መ', 'ሙ', 'ሚ', 'ማ', 'ሜ', 'ም', 'ሞ', 'ሟ', 'ረ', 'ሩ', 'ሪ', 'ራ', 'ሬ', 'ር', 'ሮ', 'ሯ', 'ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ', 'ሸ', 'ሹ', 'ሺ', 'ሻ', 'ሼ', 'ሽ', 'ሾ', 'ሿ', 'ቀ', 'ቁ', 'ቂ', 'ቃ', 'ቄ', 'ቅ', 'ቆ', 'ቋ', 'በ', 'ቡ', 'ቢ', 'ባ', 'ቤ', 'ብ', 'ቦ', 'ቧ', 'ቨ', 'ቩ', 'ቪ', 'ቫ', 'ቬ', 'ቭ', 'ቮ', 'ቯ', 'ተ', 'ቱ', 'ቲ', 'ታ', 'ቴ', 'ት', 'ቶ', 'ቷ', 'ቸ', 'ቹ', 'ቺ', 'ቻ', 'ቼ', 'ች', 'ቾ', 'ቿ', 'ኋ', 'ነ', 'ኑ', 'ኒ', 'ና', 'ኔ', 'ን', 'ኖ', 'ኗ', 'ኘ', 'ኙ', 'ኚ', 'ኛ', 'ኜ', 'ኝ', 'ኞ', 'ኟ', 'አ', 'ኡ', 'ኢ', 'ኤ', 'እ', 'ኦ', 'ኧ', 'ከ', 'ኩ', 'ኪ', 'ካ', 'ኬ', 'ክ', 'ኮ', 'ኳ', 'ወ', 'ዉ', 'ዊ', 'ዋ', 'ዌ', 'ው', 'ዎ', 'ዘ', 'ዙ', 'ዚ', 'ዛ', 'ዜ', 'ዝ', 'ዞ', 'ዟ', 'ዠ', 'ዡ', 'ዢ', 'ዣ', 'ዤ', 'ዥ', 'ዦ', 'ዧ', 'የ', 'ዩ', 'ዪ', 'ያ', 'ዬ', 'ይ', 'ዮ', 'ደ', 'ዱ', 'ዲ', 'ዳ', 'ዴ', 'ድ', 'ዶ', 'ዷ', 'ጀ', 'ጁ', 'ጂ', 'ጃ', 'ጄ', 'ጅ', 'ጆ', 'ጇ', 'ገ', 'ጉ', 'ጊ', 'ጋ', 'ጌ', 'ግ', 'ጐ', 'ጓ', 'ጔ', 'ጠ', 'ጡ', 'ጢ', 'ጣ', 'ጤ', 'ጥ', 'ጦ', 'ጧ', 'ጨ', 'ጩ', 'ጪ', 'ጫ', 'ጬ', 'ጭ', 'ጮ', 'ጯ', 'ጰ', 'ጱ', 'ጲ', 'ጳ', 'ጴ', 'ጵ', 'ጶ', 'ጷ', 'ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ', 'ፇ', 'ፈ', 'ፉ', 'ፊ', 'ፋ', 'ፌ', 'ፍ', 'ፎ', 'ፏ', 'ፐ', 'ፑ', 'ፒ', 'ፓ', 'ፔ', 'ፕ', 'ፖ']\n"
          ]
        }
      ],
      "source": [
        "supported = \"\"\"\n",
        "ሀ ሁ ሂ ሄ ህ ሆ\n",
        "ለ ሉ ሊ ላ ሌ ል ሎ ሏ\n",
        "መ ሙ ሚ ማ ሜ ም ሞ ሟ\n",
        "ረ ሩ ሪ ራ ሬ ር ሮ ሯ\n",
        "ሰ ሱ ሲ ሳ ሴ ስ ሶ ሷ\n",
        "ሸ ሹ ሺ ሻ ሼ ሽ ሾ ሿ\n",
        "ቀ ቁ ቂ ቃ ቄ ቅ ቆ ቋ\n",
        "በ ቡ ቢ ባ ቤ ብ ቦ ቧ\n",
        "ቨ ቩ ቪ ቫ ቬ ቭ ቮ ቯ\n",
        "ተ ቱ ቲ ታ ቴ ት ቶ ቷ\n",
        "ቸ ቹ ቺ ቻ ቼ ች ቾ ቿ\n",
        "ኋ\n",
        "ነ ኑ ኒ ና ኔ ን ኖ ኗ\n",
        "ኘ ኙ ኚ ኛ ኜ ኝ ኞ ኟ\n",
        "አ ኡ ኢ ኤ እ ኦ\n",
        "ኧ\n",
        "ከ ኩ ኪ ካ ኬ ክ ኮ\n",
        "ኳ\n",
        "ወ ዉ ዊ ዋ ዌ ው ዎ\n",
        "ዘ ዙ ዚ ዛ ዜ ዝ ዞ ዟ\n",
        "ዠ ዡ ዢ ዣ ዤ ዥ ዦ ዧ\n",
        "የ ዩ ዪ ያ ዬ ይ ዮ\n",
        "ደ ዱ ዲ ዳ ዴ ድ ዶ ዷ\n",
        "ጀ ጁ ጂ ጃ ጄ ጅ ጆ ጇ\n",
        "ገ ጉ ጊ ጋ ጌ ግ ጐ ጓ ጔ\n",
        "ጠ ጡ ጢ ጣ ጤ ጥ ጦ ጧ\n",
        "ጨ ጩ ጪ ጫ ጬ ጭ ጮ ጯ\n",
        "ጰ ጱ ጲ ጳ ጴ ጵ ጶ ጷ\n",
        "ፀ ፁ ፂ ፃ ፄ ፅ ፆ ፇ\n",
        "ፈ ፉ ፊ ፋ ፌ ፍ ፎ ፏ\n",
        "ፐ ፑ ፒ ፓ ፔ ፕ ፖ\n",
        "\"\"\".replace(\"\\n\",\" \").split(\" \")\n",
        "supported.insert(1, \" \")\n",
        "supported=supported[:-1]\n",
        "print(supported)\n",
        "# char_map = {}\n",
        "# char_map[\"\"] = 0\n",
        "# char_map[' '] = 1\n",
        "# index = 2\n",
        "# for c in supported:\n",
        "#     char_map[c] = index\n",
        "#     index += 1\n",
        "# index_map = {v: k for k, v in char_map.items()}\n",
        "# lan_lis = list(index_map.values())\n",
        "# print(index_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ogzcIuDtlUub"
      },
      "outputs": [],
      "source": [
        "# Mapping characters to integers\n",
        "char_to_num = keras.layers.StringLookup(vocabulary=supported, oov_token=\"\")\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nih9uRsnlVZw"
      },
      "outputs": [],
      "source": [
        "path = (\"data/resized2/\")\n",
        "# An integer scalar Tensor. The window length in samples.\n",
        "frame_length = 256\n",
        "# An integer scalar Tensor. The number of samples to step.\n",
        "frame_step = 160\n",
        "# An integer scalar Tensor. The size of the FFT to apply.\n",
        "# If not provided, uses the smallest power of 2 enclosing frame_length.\n",
        "fft_length = 384\n",
        "\n",
        "\n",
        "def encode_single_sample(wav_file, label):\n",
        "    ###########################################\n",
        "    ##  Process the Audio\n",
        "    ##########################################\n",
        "    # 1. Read wav file\n",
        "    #print(tf.get_static_value(wav_file))\n",
        "    file = tf.io.read_file(path + wav_file)\n",
        "    # 2. Decode the wav file\n",
        "    audio, _ = tf.audio.decode_wav(file)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    # 3. Change type to float\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "    # 4. Get the spectrogram\n",
        "    spectrogram = tf.signal.stft(\n",
        "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
        "    )\n",
        "    # 5. We only need the magnitude, which can be derived by applying tf.abs\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "    # 6. normalisation\n",
        "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
        "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "    ###########################################\n",
        "    ##  Process the label\n",
        "    ##########################################\n",
        "    # 7. Split the label\n",
        "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "    # 8. Map the characters in label to numbers\n",
        "    label =  char_to_num(label)\n",
        "    # 9. Return a dict as our model is expecting two inputs\n",
        "    return spectrogram, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SDudniwkqnmY"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "# Define the trainig dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_train[\"audio\"]), list(df_train[\"text\"]))\n",
        ")\n",
        "train_dataset = (\n",
        "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "# Define the validation dataset\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_val[\"audio\"]), list(df_val[\"text\"]))\n",
        ")\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1jPV4KQ2qpeG"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    # Compute the training-time loss value\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V397rTIncN7T"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNh8FdmEqp5l",
        "outputId": "fa5663f3-6085-410b-f73d-a851034c5965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DeepSpeech_2\"\n",
            "______________________________________________________________________________________________________________\n",
            " Layer (type)                                    Output Shape                                Param #          \n",
            "==============================================================================================================\n",
            " input (InputLayer)                              [(None, None, 193)]                         0                \n",
            "                                                                                                              \n",
            " expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n",
            "                                                                                                              \n",
            " conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n",
            "                                                                                                              \n",
            " conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n",
            "                                                                                                              \n",
            " conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n",
            "                                                                                                              \n",
            " conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n",
            "                                                                                                              \n",
            " conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n",
            "                                                                                                              \n",
            " conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n",
            "                                                                                                              \n",
            " reshape_2 (Reshape)                             (None, None, 1568)                          0                \n",
            "                                                                                                              \n",
            " bidirectional_1 (Bidirectional)                 (None, None, 20)                            94800            \n",
            "                                                                                                              \n",
            " dropout_10 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_2 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dropout_11 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_3 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dropout_12 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_4 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dropout_13 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_5 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dense_1 (Dense)                                 (None, None, 20)                            420              \n",
            "                                                                                                              \n",
            " dense_1_relu (ReLU)                             (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " dropout_14 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " dense_2 (Dense)                                 (None, None, 223)                           4683             \n",
            "                                                                                                              \n",
            "==============================================================================================================\n",
            "Total params: 358,815\n",
            "Trainable params: 358,687\n",
            "Non-trainable params: 128\n",
            "______________________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
        "    \"\"\"Model similar to DeepSpeech2.\"\"\"\n",
        "    # Model's input\n",
        "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
        "    # Expand the dimension to use 2D CNN.\n",
        "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
        "    # Convolution layer 1\n",
        "    x = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 41],\n",
        "        strides=[2, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_1\",\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
        "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
        "    # Convolution layer 2\n",
        "    x = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 21],\n",
        "        strides=[1, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_2\",\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
        "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
        "    # Reshape the resulted volume to feed the RNNs layers\n",
        "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
        "    # RNN layers\n",
        "    for i in range(1, rnn_layers + 1):\n",
        "        recurrent = layers.GRU(\n",
        "            units=rnn_units,\n",
        "            activation=\"tanh\",\n",
        "            recurrent_activation=\"sigmoid\",\n",
        "            use_bias=True,\n",
        "            return_sequences=True,\n",
        "            reset_after=True,\n",
        "            name=f\"gru_{i}\",\n",
        "        )\n",
        "        x = layers.Bidirectional(\n",
        "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
        "        )(x)\n",
        "        if i < rnn_layers:\n",
        "            x = layers.Dropout(rate=0.5)(x)\n",
        "    # Dense layer\n",
        "    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
        "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
        "    x = layers.Dropout(rate=0.5)(x)\n",
        "    # Classification layer\n",
        "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
        "    # Model\n",
        "    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
        "    # Optimizer\n",
        "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    # Compile the model and return\n",
        "    model.compile(optimizer=opt, loss=CTCLoss)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = build_model(\n",
        "    input_dim=fft_length // 2 + 1,\n",
        "    output_dim=char_to_num.vocabulary_size(),\n",
        "    rnn_units=10,\n",
        ")\n",
        "model.summary(line_length=110)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ioDNjjG2qqet"
      },
      "outputs": [],
      "source": [
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(result)\n",
        "    return output_text\n",
        "\n",
        "\n",
        "# A callback class to output a few transcriptions during training\n",
        "class CallbackEval(keras.callbacks.Callback):\n",
        "    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs=None):\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        for batch in self.dataset:\n",
        "            X, y = batch\n",
        "            batch_predictions = model.predict(X)\n",
        "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "            predictions.extend(batch_predictions)\n",
        "            for label in y:\n",
        "                label = (\n",
        "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "                )\n",
        "                targets.append(label)\n",
        "        wer_score = wer(targets, predictions)\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "        print(\"-\" * 100)\n",
        "        for i in np.random.randint(0, len(predictions), 2):\n",
        "            print(f\"Target    : {targets[i]}\")\n",
        "            print(f\"Prediction: {predictions[i]}\")\n",
        "            print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORXAx0jpb-Y2"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHJ1qTbbUGna",
        "outputId": "37ecc1f4-5666-41f9-bbfe-6612ada590ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ኮንፍረንሱ ን የ መሩት ስር ዊሊያም ራሪ አዲስ ፎረ ም ለአፍሪካ ኢንቬስተመንት አዲስ ራእይ እንደሆነ ገልፀዋል\n",
            "Prediction: ኞህ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : በ ኔ ላይ እምነት እንዳለው ገለፀ ልኝ\n",
            "Prediction: ጓቁህቨህ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : እድሜ አቸው ጠና ያሉ አንድ አዛውንት ገበሬ እንዲ ህ አሉ\n",
            "Prediction: ኞቁኞህቨህ \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ይህም በ ኢትዮጵያ የ ዋጋ መውደቅ ን ያስከትላል\n",
            "Prediction: ኞቁኞህቢህቨህህ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : እናንተ ም መቀበሪያ እንዳ ታጡ ተጠንቀቁ\n",
            "Prediction: ኞቁኞህ\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Let's check results on more validation samples\n",
        "predictions = []\n",
        "targets = []\n",
        "for batch in validation_dataset:\n",
        "    X, y = batch\n",
        "    batch_predictions = model.predict(X)\n",
        "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "    predictions.extend(batch_predictions)\n",
        "    for label in y:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        targets.append(label)\n",
        "wer_score = wer(targets, predictions)\n",
        "print(\"-\" * 100)\n",
        "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "print(\"-\" * 100)\n",
        "for i in np.random.randint(0, len(predictions), 5):\n",
        "    print(f\"Target    : {targets[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")\n",
        "    print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek2ELMM65w3m",
        "outputId": "f5c84c27-828c-45b0-c106-c366fcd3b412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 4610.5571----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ኮንፍረንሱ ን የ መሩት ስር ዊሊያም ራሪ አዲስ ፎረ ም ለአፍሪካ ኢንቬስተመንት አዲስ ራእይ እንደሆነ ገልፀዋል\n",
            "Prediction: ች\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : በ ኢትዮጵያ በ ድርቅ ለ ተጐዱ እስካሁን የተገኘው አርባ ሺ ዶላር ብቻ ነው\n",
            "Prediction: ፕፎቭ\n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 90s 2s/step - loss: 4610.5571 - val_loss: 4498.5913\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 4516.2471----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : አዲስ አበባ ውስጥ ያሉት ሰራተኞች ተቃውሞ የሚያቀርቡ ት ከ ከተማ ላለ መውጣት ነው\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : አዲስ አበባ ውስጥ ያሉት ሰራተኞች ተቃውሞ የሚያቀርቡ ት ከ ከተማ ላለ መውጣት ነው\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 44s 1s/step - loss: 4516.2471 - val_loss: 4346.8774\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 4408.0713----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : እድሜ አቸው ጠና ያሉ አንድ አዛውንት ገበሬ እንዲ ህ አሉ\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : በ ኢትዮጵያ በ ድርቅ ለ ተጐዱ እስካሁን የተገኘው አርባ ሺ ዶላር ብቻ ነው\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 43s 1s/step - loss: 4408.0713 - val_loss: 4174.1709\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 4274.7373----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : የ መስተዳድሩ መግለጫ ከተማዋ ስር ነቀል ለውጥ እንደሚ ያስፈልጋት ገልፆ ህዝቡ በዚህ እንዲ ሳተፍ ቢ ጠይቅ ም ጊዜያዊ መስተዳድሩ የ መዋቅር ለውጡ ን ያስፈፅማል ተብሎ አይጠበቅ ም\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : እድሜ አቸው ጠና ያሉ አንድ አዛውንት ገበሬ እንዲ ህ አሉ\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 43s 1s/step - loss: 4274.7373 - val_loss: 3970.0132\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 4102.6055----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : በ ኔ ላይ እምነት እንዳለው ገለፀ ልኝ\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : እድሜ አቸው ጠና ያሉ አንድ አዛውንት ገበሬ እንዲ ህ አሉ\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 43s 1s/step - loss: 4102.6055 - val_loss: 3740.2251\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 3894.0886----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ኮንፍረንሱ ን የ መሩት ስር ዊሊያም ራሪ አዲስ ፎረ ም ለአፍሪካ ኢንቬስተመንት አዲስ ራእይ እንደሆነ ገልፀዋል\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : በ ኢትዮጵያ በ ድርቅ ለ ተጐዱ እስካሁን የተገኘው አርባ ሺ ዶላር ብቻ ነው\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 43s 1s/step - loss: 3894.0886 - val_loss: 3485.1714\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 3644.7285----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : አዲስ አበባ ውስጥ ያሉት ሰራተኞች ተቃውሞ የሚያቀርቡ ት ከ ከተማ ላለ መውጣት ነው\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ለ ምሳሌ ዲዮ ን ደብሊን ን ፓትሪክ ኩላይቨርት ን ን ሮናልድ ዴ ቦዬርን ና የኢንተሩ ን ንዋንክዎ ካኑ ን ለ መውሰድ ድርድር ጀምረው መጨረሻው ን ሳያዩ ት ተዋል\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 43s 1s/step - loss: 3644.7285 - val_loss: 3184.9631\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 3361.1902----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : የ መስተዳድሩ መግለጫ ከተማዋ ስር ነቀል ለውጥ እንደሚ ያስፈልጋት ገልፆ ህዝቡ በዚህ እንዲ ሳተፍ ቢ ጠይቅ ም ጊዜያዊ መስተዳድሩ የ መዋቅር ለውጡ ን ያስፈፅማል ተብሎ አይጠበቅ ም\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : በ ኔ ላይ እምነት እንዳለው ገለፀ ልኝ\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 43s 1s/step - loss: 3361.1902 - val_loss: 2846.0239\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 3034.6211----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ኮንፍረንሱ ን የ መሩት ስር ዊሊያም ራሪ አዲስ ፎረ ም ለአፍሪካ ኢንቬስተመንት አዲስ ራእይ እንደሆነ ገልፀዋል\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ወደ ትንተና ውስጥ ነበር የ ገባው\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 54s 2s/step - loss: 3034.6211 - val_loss: 2481.3926\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - ETA: 0s - loss: 2683.3528----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 1.0000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : አዲስ አበባ ውስጥ ያሉት ሰራተኞች ተቃውሞ የሚያቀርቡ ት ከ ከተማ ላለ መውጣት ነው\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : የ መስተዳድሩ መግለጫ ከተማዋ ስር ነቀል ለውጥ እንደሚ ያስፈልጋት ገልፆ ህዝቡ በዚህ እንዲ ሳተፍ ቢ ጠይቅ ም ጊዜያዊ መስተዳድሩ የ መዋቅር ለውጡ ን ያስፈፅማል ተብሎ አይጠበቅ ም\n",
            "Prediction: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "30/30 [==============================] - 43s 1s/step - loss: 2683.3528 - val_loss: 2096.0242\n"
          ]
        }
      ],
      "source": [
        "# Define the number of epochs.\n",
        "epochs = 10\n",
        "# Callback function to check transcription on the val set.\n",
        "validation_callback = CallbackEval(validation_dataset)\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=[validation_callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwSs40fQ6HFo"
      },
      "source": [
        "## Model Space Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b16aeBog3a_U",
        "outputId": "7cfe18c3-929f-4d65-aa3a-090f9f1fb17c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DeepSpeech_2\"\n",
            "______________________________________________________________________________________________________________\n",
            " Layer (type)                                    Output Shape                                Param #          \n",
            "==============================================================================================================\n",
            " input (InputLayer)                              [(None, None, 193)]                         0                \n",
            "                                                                                                              \n",
            " expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n",
            "                                                                                                              \n",
            " conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n",
            "                                                                                                              \n",
            " conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n",
            "                                                                                                              \n",
            " conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n",
            "                                                                                                              \n",
            " conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n",
            "                                                                                                              \n",
            " conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n",
            "                                                                                                              \n",
            " conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n",
            "                                                                                                              \n",
            " reshape_3 (Reshape)                             (None, None, 1568)                          0                \n",
            "                                                                                                              \n",
            " bidirectional_1 (Bidirectional)                 (None, None, 20)                            94800            \n",
            "                                                                                                              \n",
            " dropout_15 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_2 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dropout_16 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_3 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dropout_17 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_4 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dropout_18 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_5 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dropout_19 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_6 (Bidirectional)                 (None, None, 20)                            1920             \n",
            "                                                                                                              \n",
            " dense_1 (Dense)                                 (None, None, 20)                            420              \n",
            "                                                                                                              \n",
            " dense_1_relu (ReLU)                             (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " dropout_20 (Dropout)                            (None, None, 20)                            0                \n",
            "                                                                                                              \n",
            " dense_3 (Dense)                                 (None, None, 223)                           4683             \n",
            "                                                                                                              \n",
            "==============================================================================================================\n",
            "Total params: 360,735\n",
            "Trainable params: 360,607\n",
            "Non-trainable params: 128\n",
            "______________________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get the model\n",
        "model = build_model(\n",
        "    input_dim=fft_length // 2 + 1,\n",
        "    output_dim=char_to_num.vocabulary_size(),\n",
        "    rnn_layers = 6,\n",
        "    rnn_units=10,\n",
        ")\n",
        "model.summary(line_length=110)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "modelling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBdGjlGrzp6GQLsspGi30p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
