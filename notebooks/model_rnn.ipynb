{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa   #for audio processing\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### Load scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import data_loader\n",
    "from preprocessing import Preprocessor\n",
    "from models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '../data/AMHARIC/data'\n",
    "SAMPLE_RATE = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data_loader(FILE_PATH)\n",
    "preprocess = Preprocessor()\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = loader.load_audios()\n",
    "audios = preprocess.preprocess_audios(audios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = loader.get_all_audios()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 15:07:28.733894: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-07 15:07:28.787673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 15:07:28.787695: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, LSTM, MaxPooling2D, Bidirectional, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 15:08:02.698149: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-07 15:08:02.698176: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-07 15:08:02.698196: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jedi): /proc/driver/nvidia/version does not exist\n",
      "2022-06-07 15:08:02.698617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 100, 150, 64)\n",
      "Model: \"ocr_model_v1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 400, 600, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 400, 600, 32  1184        ['image[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 200, 300, 32  0           ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)                 (None, 200, 300, 64  18496       ['pool1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 100, 150, 64  0           ['Conv2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 100, 9600)    0           ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 100, 64)      614464      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100, 64)      0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 100, 256)     197632      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 100, 128)    164352      ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 100, 223)     28767       ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 100, 223)     0           ['label[0][0]',                  \n",
      "                                                                  'dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,024,895\n",
      "Trainable params: 1,024,895\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = layers.Input(\n",
    "    shape=(400, 600, 4), name=\"image\", dtype=\"float32\"\n",
    ")\n",
    "labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    32,\n",
    "    (3, 3),\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    padding=\"same\",\n",
    "    name=\"Conv1\",\n",
    ")(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    64,\n",
    "    (3, 3),\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    padding=\"same\",\n",
    "    name=\"Conv2\",\n",
    ")(x)\n",
    "x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "print(x.type_spec.shape)\n",
    "\n",
    "new_shape = (x.type_spec.shape[-3], x.type_spec.shape[-2]*x.type_spec.shape[-1])\n",
    "x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "x = layers.Dense(\n",
    "    len(char_encoder.classes_) + 1, activation=\"softmax\", name=\"dense2\"\n",
    ")(x)\n",
    "\n",
    "output = CTC(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "# Model Definition\n",
    "model = keras.models.Model(\n",
    "    inputs=[input_img, labels], outputs=output, name=\"mod\"\n",
    ")\n",
    "# add Optimizer\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "# Compile the model and return\n",
    "model.compile(optimizer=opt)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400, 600, 4) (100, 20)\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 178s 7s/step - loss: 179.5235\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 15s 591ms/step - loss: 79.7463\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 77.2045\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 9s 352ms/step - loss: 76.8000\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 76.5132\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 76.2412\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 75.9082\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 9s 348ms/step - loss: 75.6581\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 9s 348ms/step - loss: 75.4062\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 75.0994\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 8s 299ms/step - loss: 75.0069\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 74.6976\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 74.5844\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 74.3466\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 74.2129\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 73.9090\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 73.6821\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 24s 1s/step - loss: 73.6034\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 9s 369ms/step - loss: 73.4017\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 73.2320\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 72.9277\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 72.8271\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 72.6197\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 72.5002\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 72.3564\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 72.2861\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 72.0649\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 71.9551\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 71.8430\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 71.5518\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 71.3909\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 71.3431\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 71.1264\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 70.9310\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 70.7347\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 70.4410\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 70.1714\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 69.9982\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 69.7614\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 69.5999\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 69.3921\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 9s 358ms/step - loss: 69.3958\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 11s 449ms/step - loss: 68.8182\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 68.6286\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 68.4453\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 67.9458\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 67.6439\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 67.2430\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 8s 299ms/step - loss: 66.8892\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 66.7148\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 66.2732\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 65.8114\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 65.4285\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 65.0325\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 64.4299\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 64.4972\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 63.8950\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 63.4470\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 63.2486\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 62.7031\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 62.6100\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 62.0510\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 61.5878\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 61.3086\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 60.7862\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 60.5882\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 60.4040\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 59.6178\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 59.2256\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 58.4831\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 58.2432\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 58.1013\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 57.7754\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 57.1608\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 56.5050\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 55.8733\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 55.5391\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 55.0840\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 54.6873\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 53.9109\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 53.8844\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 53.3677\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 52.9022\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 51.9531\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 9s 348ms/step - loss: 51.8037\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 51.2695\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 51.0928\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 50.3911\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 49.9015\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 49.3620\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 48.6205\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 48.7923\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 48.4103\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 48.0543\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 47.0197\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 46.7747\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 46.5842\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 46.2716\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 44.9312\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 44.8657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5c4407760>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "print(X_train.shape, np.array(y_train).shape)\n",
    "model.fit([X_train, np.array(y_train)], batch_size = 4, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41a7d76cbfab68975011cfa19a8c6cf4cafba4d214b4a3adbe3593ebca678651"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('speech')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
